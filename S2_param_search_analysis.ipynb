{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed control in biological sequence-generating network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conductance-based LIF network. Single-neuron voltage dynamics:\n",
    "\n",
    "$$C_m \\frac{dV}{dt} = g_l[E_l - V(t)] + g_e(t)[E_e - V(t)] + g_i(t)[E_i - V(t)] + I_{ext}(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time-varying conductances $g_e(t)$ and $g_i(t)$ are exponentially filtered sums of spike trains from upstream neurons $j$, with time constants $\\tau_e$ and $\\tau_i$ and weighted by $W_e^{ij}$ and $W_i^{ij}$, respectively (convention: weight to $i$ from $j$):\n",
    "\n",
    "$$\\tau_e\\frac{dg^i_e}{dt} = -g^i_e + \\sum_j W_e^{ij} \\sum_{t_k^j} \\delta(t - t_k^j)$$\n",
    "\n",
    "$$\\tau_i\\frac{dg^i_i}{dt} = -g^i_i + \\sum_j W_i^{ij} \\sum_{t_k^j} \\delta(t - t_k^j)$$\n",
    "\n",
    "where $t_k^j$ are the spike times in the $j$-th neuron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inhibitory conductance assumption:\n",
    "\n",
    "$$\\tau_i\\frac{dg^i_i}{dt} = -g^i_i + N_{i} W_{i-e} r_{i} \\tau_i\\ + g_{UVA} $$\n",
    "\n",
    "$$ g^i_i(t) = A^i e^{-t/\\tau_i} + C^i $$\n",
    "\n",
    "$$ g^i_i = N_{i} W_{i-e} r_{i} \\tau_i\\ + g_{UVA} $$\n",
    "\n",
    "$$C_m \\frac{dV}{dt} = g_l[E_l - V(t)] + g_e(1-e^{-\\frac{t}{\\tau}})[E_e - V(t)] + (N_{i} W_{i-e} r_{i} \\tau_i\\ + g_{UVA})[E_i - V(t)] + I_{ext}(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "All param values are in SI units, with capacitance and conductance per cm$^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from copy import deepcopy as copy\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from aux import Generic\n",
    "from disp import set_font_size, get_spaced_colors\n",
    "from ntwk import LIFNtwkG, join_w\n",
    "\n",
    "from utils.general import *\n",
    "from utils.file_io import *\n",
    "\n",
    "cc = np.concatenate\n",
    "\n",
    "# PARAMS\n",
    "## NEURON AND NETWORK MODEL\n",
    "M = Generic(\n",
    "    # Excitatory membrane\n",
    "    C_M_E=1e-6,  # membrane capacitance\n",
    "    G_L_E=.1e-3,  # membrane leak conductance (T_M (s) = C_M (F/cm^2) / G_L (S/cm^2))\n",
    "    E_L_E=-.06,  # membrane leak potential (V)\n",
    "    V_TH_E=-.05,  # membrane spike threshold (V)\n",
    "    T_R_E=1.6e-3,  # refractory period (s)\n",
    "    \n",
    "    # Inhibitory membrane\n",
    "    #C_M_I=1e-6,\n",
    "    #G_L_E=.1e-3, \n",
    "    #E_L_I=-.06,\n",
    "    #V_TH_E=-.05,\n",
    "    #T_R_I=.002,\n",
    "    \n",
    "    # syn rev potentials and decay times\n",
    "    E_E=0, E_I=-.08, T_E=.002, T_I=.002,\n",
    "\n",
    "    # NTWK ARCHITECTURE\n",
    "    N_L=40,  # num chain links\n",
    "    N_L_E=30,  # num E nrns per chain link\n",
    "    W_E_E_R=0.005e-3,  # E-E recurrent cxns w/in chain link\n",
    "    W_E_E_F=0.01e-3,  # E-E feed-forward from one link to next\n",
    "    W_U_E_I=0.05e-3,  # I->E input weights\n",
    "    \n",
    "    # OTHER INPUTS\n",
    "    SGM_N=.5e-9,  # noise level (A*sqrt(s)) \n",
    "    I_EXT_B=0,  # additional baseline current input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sifting through results of the parameter search\n",
    "Here's some code to load batches of experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spk_tms_for_link(spks_t, spks_c, idx, n_l_e):\n",
    "    link_start_idx = idx * n_l_e\n",
    "    window = (spks_c >= link_start_idx) & (spks_c < (link_start_idx + n_l_e))\n",
    "    return spks_t[window]\n",
    "\n",
    "def tms_for_link(spks_t, spks_c, n_l, n_l_e):\n",
    "    return [spk_tms_for_link(spks_t, spks_c, i, n_l_e) for i in range(n_l)]\n",
    "\n",
    "def last_spk_tm(tms_p_link):\n",
    "    l = len(tms_p_link)\n",
    "    for i in range(l):\n",
    "        tms_for_link = tms_p_link[l - i - 1]\n",
    "        if len(tms_for_link) > 0:\n",
    "            return tms_for_link[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for loading and scanning experiments for interesting results by batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batches(batch_path):\n",
    "    fs = [f for f in sorted(all_files_with_name_frags(batch_path, 'batch_'))]\n",
    "    for f_idx, f in enumerate(fs):\n",
    "        batch_data = pickle.load(open(os.path.join(batch_path, f), 'rb'))\n",
    "        yield batch_data\n",
    "        \n",
    "slp_ratio_thrsh = 1.7\n",
    "\n",
    "def process_single_exp(experiment_results, m):\n",
    "    x = np.arange(m.N_L) + 1\n",
    "    results = []\n",
    "    \n",
    "    keep = True\n",
    "    first_inv_slope = None\n",
    "    inv_slp_ratio = None\n",
    "    \n",
    "    experiment_results = experiment_results[0] if type(experiment_results) is list else experiment_results\n",
    "\n",
    "    for frq_idx, frq_res in enumerate(experiment_results):\n",
    "\n",
    "        tms_p_link = tms_for_link(frq_res['spks_t'], frq_res['spks_c'], m.N_L, m.N_L_E)\n",
    "        mean_tms_p_link = np.array([np.mean(tms_for_link) for tms_for_link in tms_p_link])\n",
    "        std_tms_p_link = np.array([np.std(tms_for_link) for tms_for_link in tms_p_link])\n",
    "\n",
    "        mean_of_std = np.mean(std_tms_p_link[~np.isnan(std_tms_p_link)])\n",
    "        std_of_std = np.std(std_tms_p_link[~np.isnan(std_tms_p_link)])\n",
    "\n",
    "        counts_per_link = np.array(map_to_list(lambda l: l.size, tms_p_link))\n",
    "        mean_cnts_p_link = np.mean(counts_per_link[counts_per_link > 0])\n",
    "        std_cnts_p_link = np.std(counts_per_link[counts_per_link > 0])\n",
    "\n",
    "#         if ((len(tms_p_link[-1]) == 0 and (last_spk_tm(tms_p_link) < (.3 - 0.01)))\n",
    "#             or std_of_std / mean_of_std > 0.3\n",
    "#             or std_cnts_p_link / mean_cnts_p_link > 0.3\n",
    "#             or mean_cnts_p_link > 8 * m.N_L_E\n",
    "#             or mean_cnts_p_link < 2 * m.N_L_E):\n",
    "#             keep = False\n",
    "#             break\n",
    "\n",
    "        slp, icpt = stats.linregress(x, mean_tms_p_link)[:2]\n",
    "        if frq_idx == 0:\n",
    "            first_inv_slope = 1./slp\n",
    "        elif frq_idx == 2:\n",
    "            if first_inv_slope is None:\n",
    "                keep = False\n",
    "                break\n",
    "            inv_slp_ratio = (1./slp) / first_inv_slope\n",
    "            if not np.isnan(inv_slp_ratio):\n",
    "                print(inv_slp_ratio)\n",
    "            if np.isnan(inv_slp_ratio) or inv_slp_ratio < slp_ratio_thrsh:\n",
    "                keep = False\n",
    "                break\n",
    "        results.append([mean_tms_p_link, std_tms_p_link, slp, icpt, tms_p_link])\n",
    "    if keep:\n",
    "        return (results, inv_slp_ratio)\n",
    "\n",
    "def parse_param_results(all_results_for_params, m):\n",
    "    if type(all_results_for_params[0]) is list:\n",
    "        l = len(all_results_for_params)\n",
    "        processed = [process_single_exp(res, m) for res in all_results_for_params]\n",
    "        for el in processed:\n",
    "            if el is None:\n",
    "                return None\n",
    "        return processed\n",
    "    else:\n",
    "        processed = process_single_exp(all_results_for_params, m)\n",
    "        if processed is not None:\n",
    "            return [processed]\n",
    "        \n",
    "def scan_batch(batch_results, batch_params, m, batch_idx):\n",
    "    x = np.arange(m.N_L) + 1\n",
    "    passing_scan = []\n",
    "\n",
    "    for r in zip(batch_results, batch_params):\n",
    "        (all_results_for_params, params) = r\n",
    "        processed = parse_param_results(all_results_for_params, m)\n",
    "        if processed is not None:\n",
    "            passing_scan.append((params, processed))\n",
    "\n",
    "    for idx, (params, processed) in enumerate(passing_scan):\n",
    "        print(params)\n",
    "        inv_slope_rs = [inv_slope_r for res, inv_slope_r in processed]\n",
    "        print(np.mean(inv_slope_rs))\n",
    "        print(np.std(inv_slope_rs))\n",
    "        \n",
    "        for frq_idx, frq_res in enumerate(processed[0][0]):\n",
    "            (mean_tms_p_link, std_tms_p_link, slp, icpt, tms_p_link) = frq_res\n",
    "            gs = gridspec.GridSpec(2, 1)\n",
    "            fig = plt.figure(figsize=(10, 10), tight_layout=True)\n",
    "            axs = [fig.add_subplot(gs[0]), fig.add_subplot(gs[1])]\n",
    "            axs[0].set_title(f'index: {batch_idx}{idx} freq: {frq_idx * 400} params:' + ' '.join(map_to_list(lambda p_i: f'{p_i}', params)))\n",
    "            axs[0].fill_between(x, mean_tms_p_link - std_tms_p_link, mean_tms_p_link + std_tms_p_link, color='red', alpha=0.25)\n",
    "            axs[0].scatter(x, mean_tms_p_link, s=3, c='red')\n",
    "            axs[0].set_ylim(0, 0.3)\n",
    "            axs[0].set_xlim(0, m.N_L)\n",
    "\n",
    "            for l_cntr in range(m.N_L):\n",
    "                y = l_cntr * np.ones(len(tms_p_link[l_cntr])) + 1\n",
    "                axs[1].scatter(tms_p_link[l_cntr], y + .2 * np.random.randn(len(y)), s=5, c='black', zorder=0)\n",
    "                axs[1].set_ylim(0, m.N_L)\n",
    "        print('')\n",
    "    return passing_scan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0479397152874153\n",
      "0.9632660766793876\n"
     ]
    }
   ],
   "source": [
    "batch_path = './data/exp_2020-06-23--12:37'\n",
    "\n",
    "params = pickle.load(open(os.path.join(batch_path, 'params.p'), 'rb'))\n",
    "config = pickle.load(open(os.path.join(batch_path, 'config.p'), 'rb'))\n",
    "\n",
    "results_meeting_criteria = []\n",
    "\n",
    "for batch_idx, batch_data in enumerate(load_batches(batch_path)):\n",
    "    batch_start = batch_idx * config['batch_size']\n",
    "    batch_end = np.min([batch_start + config['batch_size'], len(params)])\n",
    "    results_meeting_criteria.append(scan_batch(batch_data, params[batch_start:batch_end], M, batch_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
